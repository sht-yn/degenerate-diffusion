{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f2cb37e8",
   "metadata": {},
   "source": [
    "# degenerate_diffusion を用いた閉形式推定ノートブック\n",
    "このノートでは、旧 `degenerate_diffusion_general.ipynb` の閉形式推定ロジックを、`degenerate_diffusion` パッケージに実装されたコンポーネントを利用して再構成します。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bda2aec4",
   "metadata": {},
   "source": [
    "## 1. ディレクトリとテンプレートの準備\n",
    "出力を整理するために `notebooks/closed_form` ディレクトリとプレースホルダーのテンプレート notebook を用意します。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0eaf65c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import nbformat\n",
    "\n",
    "NOTEBOOK_DIR = Path(\"notebooks/closed_form\")\n",
    "NOTEBOOK_DIR.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "TEMPLATE_PATH = NOTEBOOK_DIR / \"template_placeholder.ipynb\"\n",
    "if not TEMPLATE_PATH.exists():\n",
    "    template_nb = nbformat.v4.new_notebook()\n",
    "    template_nb[\"cells\"] = []\n",
    "    TEMPLATE_PATH.write_text(nbformat.writes(template_nb), encoding=\"utf-8\")\n",
    "\n",
    "TEMPLATE_PATH"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c6078c0",
   "metadata": {},
   "source": [
    "## 2. インポートと基本設定\n",
    "数値計算や可視化、`degenerate_diffusion` の主要クラスを読み込み、JAX を倍精度モードに切り替えます。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e99e43ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import jax\n",
    "import jax.numpy as jnp\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import japanize_matplotlib  # noqa: F401\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "from sympy import Array, symbols\n",
    "\n",
    "from degenerate_diffusion.processes.degenerate_diffusion_process_jax import DegenerateDiffusionProcess\n",
    "from degenerate_diffusion.evaluation.likelihood_evaluator_jax import LikelihoodEvaluator\n",
    "from degenerate_diffusion.estimation.parameter_estimator import newton_solve\n",
    "from degenerate_diffusion.estimation.loop_estimation_algorithm import LoopEstimationAlgorithm\n",
    "\n",
    "jax.config.update(\"jax_enable_x64\", True)\n",
    "sns.set_theme(style=\"whitegrid\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47332b60",
   "metadata": {},
   "source": [
    "## 3. モデル記述とシミュレーション設定\n",
    "SymPy でモデルを定義し、`DegenerateDiffusionProcess` と `LikelihoodEvaluator` を構築、さらに推定で用いる真のパラメータや初期値・制約をまとめます。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75c8a29e",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_sym = Array([symbols(\"x\")])\n",
    "y_sym = Array([symbols(\"y\")])\n",
    "theta1_sym = Array([symbols(\"theta10\")])\n",
    "theta2_sym = Array(symbols(\"theta20 theta21\"))\n",
    "theta3_sym = Array(symbols(\"theta30 theta31\"))\n",
    "\n",
    "A_expr = Array([theta2_sym[0] * y_sym[0] + theta2_sym[1] - x_sym[0]])\n",
    "B_expr = Array([[theta1_sym[0]]])\n",
    "H_expr = Array([(theta3_sym[1] - x_sym[0] - y_sym[0] ** 3 + y_sym[0]) / theta3_sym[0]])\n",
    "\n",
    "process = DegenerateDiffusionProcess(\n",
    "    x=x_sym,\n",
    "    y=y_sym,\n",
    "    theta_1=theta1_sym,\n",
    "    theta_2=theta2_sym,\n",
    "    theta_3=theta3_sym,\n",
    "    A=A_expr,\n",
    "    B=B_expr,\n",
    "    H=H_expr,\n",
    " )\n",
    "likelihood = LikelihoodEvaluator(process)\n",
    "\n",
    "sim_config = {\n",
    "    \"t_max\": 100.0,\n",
    "    \"burn_in\": 20.0,\n",
    "    \"dt\": 0.001,\n",
    "    \"h\": 0.05,\n",
    "    \"num_seeds\": 40,\n",
    "    \"k0_max\": 3,\n",
    "}\n",
    "\n",
    "true_theta = (\n",
    "    jnp.array([0.7]),\n",
    "    jnp.array([0.4, 0.6]),\n",
    "    jnp.array([1.2, 0.1]),\n",
    ")\n",
    "initial_theta = (\n",
    "    jnp.array([0.9]),\n",
    "    jnp.array([0.3, 0.5]),\n",
    "    jnp.array([1.0, 0.0]),\n",
    " )\n",
    "\n",
    "parameter_bounds = {\n",
    "    \"theta1\": (jnp.array([0.1]), jnp.array([2.0])),\n",
    "    \"theta2\": (jnp.array([-1.5, -1.5]), jnp.array([1.5, 1.5])),\n",
    "    \"theta3\": (jnp.array([0.2, -5.0]), jnp.array([5.0, 5.0])),\n",
    "}\n",
    "sim_config"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4941201b",
   "metadata": {},
   "source": [
    "## 4. `degenerate_diffusion` からのサンプラー呼び出し\n",
    "`DegenerateDiffusionProcess.simulate` を使って観測系列 $(x_t, y_t)$ を生成するユーティリティを定義します。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f3ad66b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def simulate_observations(process: DegenerateDiffusionProcess, theta: tuple[jnp.ndarray, jnp.ndarray, jnp.ndarray], config: dict, seed: int):\n",
    "    x_series, y_series = process.simulate(\n",
    "        true_theta=theta,\n",
    "        t_max=config[\"t_max\"],\n",
    "        h=config[\"h\"],\n",
    "        burn_out=config[\"burn_in\"],\n",
    "        dt=config[\"dt\"],\n",
    "        seed=seed,\n",
    "    )\n",
    "    time_grid = jnp.arange(x_series.shape[0]) * config[\"h\"]\n",
    "    # 1次元のため squeeze して扱いやすくする\n",
    "    x_flat = jnp.asarray(x_series).reshape(-1)\n",
    "    y_flat = jnp.asarray(y_series).reshape(-1)\n",
    "    return time_grid, x_flat, y_flat\n",
    "\n",
    "\n",
    "time_sample, x_sample, y_sample = simulate_observations(process, true_theta, sim_config, seed=0)\n",
    "pd.DataFrame({\"t\": np.asarray(time_sample), \"x\": np.asarray(x_sample), \"y\": np.asarray(y_sample)}).head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d40379f",
   "metadata": {},
   "source": [
    "## 5. 演算子 $L_0, \\tilde{L}_0, L_1, L_2, L_3$ の関数化\n",
    "`LikelihoodEvaluator` が内部で構築するシンボリック演算子を、数値計算で再利用できるように関数テーブルとしてまとめます。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "535063d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from functools import lru_cache\n",
    "\n",
    "max_operator_order = sim_config[\"k0_max\"] + 3\n",
    "\n",
    "@lru_cache(maxsize=None)\n",
    "def get_L0_tables(max_order: int = max_operator_order):\n",
    "    \"\"\"`L_0` を様々な基底に適用した関数タプルをキャッシュして返す。\"\"\"\n",
    "    tables = {\n",
    "        \"x\": tuple(likelihood.generator.L_0(process.x, m).func for m in range(max_order + 1)),\n",
    "        \"y\": tuple(likelihood.generator.L_0(process.y, m).func for m in range(max_order + 2)),\n",
    "        \"H\": tuple(\n",
    "            likelihood.generator.L_0(process.H.expr[0], m).func for m in range(max_order + 2)\n",
    "        ),\n",
    "    }\n",
    "    return tables\n",
    "\n",
    "def evaluate_L0_component(table_key: str, order: int, x_val: jnp.ndarray, y_val: jnp.ndarray, theta: tuple[jnp.ndarray, jnp.ndarray, jnp.ndarray]):\n",
    "    tables = get_L0_tables()\n",
    "    theta_1_val, theta_2_val, theta_3_val = theta\n",
    "    func = tables[table_key][order]\n",
    "    return func(x_val, y_val, theta_1_val, theta_2_val, theta_3_val)\n",
    "\n",
    "# サンプルデータ点で L0[H] を確認\n",
    "sample_index = 5\n",
    "x_point = jnp.asarray([x_sample[sample_index]])\n",
    "y_point = jnp.asarray([y_sample[sample_index]])\n",
    "evaluate_L0_component(\"H\", 0, x_point, y_point, true_theta)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41be09c9",
   "metadata": {},
   "source": [
    "## 6. 更新関数の再実装\n",
    "`LikelihoodEvaluator` が提供する疑似尤度関数と `newton_solve` を組み合わせ、段階ごとの推定器更新関数 `update_1`, `update_2`, `update_3`, `update_1_prime` を実装します。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "098081bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def _bounds_to_tuples(bounds_array: tuple[jnp.ndarray, jnp.ndarray]):\n",
    "    lower, upper = bounds_array\n",
    "    lower_np = np.asarray(lower, dtype=float)\n",
    "    upper_np = np.asarray(upper, dtype=float)\n",
    "    return [(low, high) for low, high in zip(lower_np, upper_np)]\n",
    "\n",
    "theta1_bounds = _bounds_to_tuples(parameter_bounds[\"theta1\"])\n",
    "theta2_bounds = _bounds_to_tuples(parameter_bounds[\"theta2\"])\n",
    "theta3_bounds = _bounds_to_tuples(parameter_bounds[\"theta3\"])\n",
    "\n",
    "newton_options = {\n",
    "    \"max_iters\": 2000,\n",
    "    \"tol\": 1e-7,\n",
    "    \"damping\": 0.3,\n",
    "    \"log_interval\": None,\n",
    "}\n",
    "\n",
    "def update_1(theta_bar: tuple[jnp.ndarray, jnp.ndarray, jnp.ndarray], x_series: jnp.ndarray, y_series: jnp.ndarray, *, h: float, k: int, initial_guess: jnp.ndarray | None = None, my_setting: bool = True) -> jnp.ndarray:\n",
    "    theta_1_bar, theta_2_bar, theta_3_bar = theta_bar\n",
    "    l1_eval = likelihood.make_quasi_likelihood_l1_evaluator(x_series, y_series, h, k, my_setting=my_setting)\n",
    "    init = np.asarray(initial_guess if initial_guess is not None else theta_1_bar)\n",
    "    objective = lambda theta_val: l1_eval(jnp.asarray(theta_val), theta_1_bar, theta_2_bar, theta_3_bar)\n",
    "    solution = newton_solve(objective, theta1_bounds, init, **newton_options)\n",
    "    return jnp.asarray(solution)\n",
    "\n",
    "def update_1_prime(theta_bar: tuple[jnp.ndarray, jnp.ndarray, jnp.ndarray], x_series: jnp.ndarray, y_series: jnp.ndarray, *, h: float, k: int, initial_guess: jnp.ndarray | None = None) -> jnp.ndarray:\n",
    "    theta_1_bar, theta_2_bar, theta_3_bar = theta_bar\n",
    "    l1p_eval = likelihood.make_quasi_likelihood_l1_prime_evaluator(x_series, y_series, h, k)\n",
    "    init = np.asarray(initial_guess if initial_guess is not None else theta_1_bar)\n",
    "    objective = lambda theta_val: l1p_eval(jnp.asarray(theta_val), theta_1_bar, theta_2_bar, theta_3_bar)\n",
    "    solution = newton_solve(objective, theta1_bounds, init, **newton_options)\n",
    "    return jnp.asarray(solution)\n",
    "\n",
    "def update_2(theta_bar: tuple[jnp.ndarray, jnp.ndarray, jnp.ndarray], x_series: jnp.ndarray, y_series: jnp.ndarray, *, h: float, k: int, initial_guess: jnp.ndarray | None = None) -> jnp.ndarray:\n",
    "    theta_1_bar, theta_2_bar, theta_3_bar = theta_bar\n",
    "    l2_eval = likelihood.make_quasi_likelihood_l2_evaluator(x_series, y_series, h, k)\n",
    "    init = np.asarray(initial_guess if initial_guess is not None else theta_2_bar)\n",
    "    objective = lambda theta_val: l2_eval(jnp.asarray(theta_val), theta_1_bar, theta_2_bar, theta_3_bar)\n",
    "    solution = newton_solve(objective, theta2_bounds, init, **newton_options)\n",
    "    return jnp.asarray(solution)\n",
    "\n",
    "def update_3(theta_bar: tuple[jnp.ndarray, jnp.ndarray, jnp.ndarray], x_series: jnp.ndarray, y_series: jnp.ndarray, *, h: float, k: int, initial_guess: jnp.ndarray | None = None) -> jnp.ndarray:\n",
    "    theta_1_bar, theta_2_bar, theta_3_bar = theta_bar\n",
    "    l3_eval = likelihood.make_quasi_likelihood_l3_evaluator(x_series, y_series, h, k)\n",
    "    init = np.asarray(initial_guess if initial_guess is not None else theta_3_bar)\n",
    "    objective = lambda theta_val: l3_eval(jnp.asarray(theta_val), theta_1_bar, theta_2_bar, theta_3_bar)\n",
    "    solution = newton_solve(objective, theta3_bounds, init, **newton_options)\n",
    "    return jnp.asarray(solution)\n",
    "\n",
    "update_1((initial_theta[0], initial_theta[1], initial_theta[2]), x_sample, y_sample, h=sim_config[\"h\"], k=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec929954",
   "metadata": {},
   "source": [
    "## 7. メイン推定ループと $k_0$ 探索\n",
    "Monte Carlo サンプルごとに疑似尤度を段階的に最大化し、未スケール推定量と正規化済み推定量を集計します。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a646413",
   "metadata": {},
   "outputs": [],
   "source": [
    "def _flatten_theta(theta_tuple: tuple[jnp.ndarray, jnp.ndarray, jnp.ndarray]) -> dict[str, float]:\n",
    "    theta_1_val, theta_2_val, theta_3_val = theta_tuple\n",
    "    return {\n",
    "        \"theta10\": float(theta_1_val[0]),\n",
    "        \"theta20\": float(theta_2_val[0]),\n",
    "        \"theta21\": float(theta_2_val[1]),\n",
    "        \"theta30\": float(theta_3_val[0]),\n",
    "        \"theta31\": float(theta_3_val[1]),\n",
    "    }\n",
    "\n",
    "def _compute_scaled(theta_tuple: tuple[jnp.ndarray, jnp.ndarray, jnp.ndarray], true_theta_tuple: tuple[jnp.ndarray, jnp.ndarray, jnp.ndarray], n_transitions: int, h: float, k: int) -> dict[str, float]:\n",
    "    theta1_hat, theta2_hat, theta3_hat = theta_tuple\n",
    "    theta1_true, theta2_true, theta3_true = true_theta_tuple\n",
    "    rate1 = likelihood.a(n_transitions, h, k, 1)\n",
    "    rate2 = likelihood.a(n_transitions, h, k, 2)\n",
    "    rate3 = likelihood.a(n_transitions, h, k, 3)\n",
    "    scaled_theta1 = (theta1_hat - theta1_true) / rate1\n",
    "    scaled_theta2 = (theta2_hat - theta2_true) / rate2\n",
    "    scaled_theta3 = (theta3_hat - theta3_true) / rate3\n",
    "    return {\n",
    "        \"theta10_scaled\": float(scaled_theta1[0]),\n",
    "        \"theta20_scaled\": float(scaled_theta2[0]),\n",
    "        \"theta21_scaled\": float(scaled_theta2[1]),\n",
    "        \"theta30_scaled\": float(scaled_theta3[0]),\n",
    "        \"theta31_scaled\": float(scaled_theta3[1]),\n",
    "    }\n",
    "\n",
    "def run_closed_form_estimation(config: dict, true_theta_tuple: tuple[jnp.ndarray, jnp.ndarray, jnp.ndarray], initial_theta_tuple: tuple[jnp.ndarray, jnp.ndarray, jnp.ndarray]) -> tuple[pd.DataFrame, pd.DataFrame]:\n",
    "    records: list[dict[str, float | int | str]] = []\n",
    "    scaled_records: list[dict[str, float | int | str]] = []\n",
    "    seed_iter = range(config[\"num_seeds\"])\n",
    "    for seed in tqdm(seed_iter, desc=\"Monte Carlo seeds\"):\n",
    "        _, x_series, y_series = simulate_observations(process, true_theta_tuple, config, seed=seed)\n",
    "        n_transitions = int(x_series.shape[0] - 1)\n",
    "        theta_stage = tuple(jnp.asarray(comp) for comp in initial_theta_tuple)\n",
    "        for k in range(1, config[\"k0_max\"] + 1):\n",
    "            theta1_hat = update_1(theta_stage, x_series, y_series, h=config[\"h\"], k=k)\n",
    "            theta2_hat = update_2((theta1_hat, theta_stage[1], theta_stage[2]), x_series, y_series, h=config[\"h\"], k=k)\n",
    "            theta3_hat = update_3((theta1_hat, theta2_hat, theta_stage[2]), x_series, y_series, h=config[\"h\"], k=k)\n",
    "            theta_stage = (theta1_hat, theta2_hat, theta3_hat)\n",
    "\n",
    "            flat_vals = _flatten_theta(theta_stage)\n",
    "            scaled_vals = _compute_scaled(theta_stage, true_theta_tuple, n_transitions, config[\"h\"], k)\n",
    "            records.append({\n",
    "                \"seed\": seed,\n",
    "                \"stage\": \"stage\",\n",
    "                \"k\": k,\n",
    "                **flat_vals,\n",
    "            })\n",
    "            scaled_records.append({\n",
    "                \"seed\": seed,\n",
    "                \"stage\": \"stage\",\n",
    "                \"k\": k,\n",
    "                **scaled_vals,\n",
    "            })\n",
    "\n",
    "        theta1_prime = update_1_prime(theta_stage, x_series, y_series, h=config[\"h\"], k=config[\"k0_max\"])\n",
    "        theta_final = (theta1_prime, theta_stage[1], theta_stage[2])\n",
    "        flat_vals_prime = _flatten_theta(theta_final)\n",
    "        scaled_vals_prime = _compute_scaled(\n",
    "            theta_final, true_theta_tuple, n_transitions, config[\"h\"], config[\"k0_max\"]\n",
    "        )\n",
    "        records.append({\n",
    "            \"seed\": seed,\n",
    "            \"stage\": \"prime\",\n",
    "            \"k\": config[\"k0_max\"],\n",
    "            **flat_vals_prime,\n",
    "        })\n",
    "        scaled_records.append({\n",
    "            \"seed\": seed,\n",
    "            \"stage\": \"prime\",\n",
    "            \"k\": config[\"k0_max\"],\n",
    "            **scaled_vals_prime,\n",
    "        })\n",
    "\n",
    "    records_df = pd.DataFrame.from_records(records)\n",
    "    scaled_df = pd.DataFrame.from_records(scaled_records)\n",
    "    return records_df, scaled_df\n",
    "\n",
    "raw_estimates_df, scaled_estimates_df = run_closed_form_estimation(sim_config, true_theta, initial_theta)\n",
    "raw_estimates_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc4a5e31",
   "metadata": {},
   "source": [
    "## 8. 集計と統計指標\n",
    "推定結果から平均・分散・RMSE を計算し、真値との差を定量化します。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b23bc65f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def summarize_raw_estimates(raw_df: pd.DataFrame, true_theta_tuple: tuple[jnp.ndarray, jnp.ndarray, jnp.ndarray]) -> pd.DataFrame:\n",
    "    parameter_names = [\"theta10\", \"theta20\", \"theta21\", \"theta30\", \"theta31\"]\n",
    "    true_values = {\n",
    "        \"theta10\": float(true_theta_tuple[0][0]),\n",
    "        \"theta20\": float(true_theta_tuple[1][0]),\n",
    "        \"theta21\": float(true_theta_tuple[1][1]),\n",
    "        \"theta30\": float(true_theta_tuple[2][0]),\n",
    "        \"theta31\": float(true_theta_tuple[2][1]),\n",
    "    }\n",
    "    rows: list[dict[str, float | int | str]] = []\n",
    "    for (stage, k), group in raw_df.groupby([\"stage\", \"k\"]):\n",
    "        row: dict[str, float | int | str] = {\"stage\": stage, \"k\": k}\n",
    "        for name in parameter_names:\n",
    "            values = group[name]\n",
    "            true_val = true_values[name]\n",
    "            row[f\"{name}_mean\"] = float(values.mean())\n",
    "            row[f\"{name}_std\"] = float(values.std(ddof=1))\n",
    "            row[f\"{name}_rmse\"] = float(np.sqrt(((values - true_val) ** 2).mean()))\n",
    "        rows.append(row)\n",
    "    return pd.DataFrame(rows)\n",
    "\n",
    "def summarize_scaled_estimates(scaled_df: pd.DataFrame) -> pd.DataFrame:\n",
    "    scaled_names = [\"theta10_scaled\", \"theta20_scaled\", \"theta21_scaled\", \"theta30_scaled\", \"theta31_scaled\"]\n",
    "    rows: list[dict[str, float | int | str]] = []\n",
    "    for (stage, k), group in scaled_df.groupby([\"stage\", \"k\"]):\n",
    "        row: dict[str, float | int | str] = {\"stage\": stage, \"k\": k}\n",
    "        for name in scaled_names:\n",
    "            row[f\"{name}_mean\"] = float(group[name].mean())\n",
    "            row[f\"{name}_std\"] = float(group[name].std(ddof=1))\n",
    "        rows.append(row)\n",
    "    return pd.DataFrame(rows)\n",
    "\n",
    "raw_summary_df = summarize_raw_estimates(raw_estimates_df, true_theta)\n",
    "scaled_summary_df = summarize_scaled_estimates(scaled_estimates_df)\n",
    "raw_summary_df.round(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab327bc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "scaled_summary_df.round(4)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "666ab31a",
   "metadata": {},
   "source": [
    "## 9. 可視化\n",
    "推定量と正規化推定量の分布を `seaborn` のボックスプロットで確認します。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14d3cc62",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_estimation_distributions(raw_df: pd.DataFrame, scaled_df: pd.DataFrame) -> None:\n",
    "    raw_long = raw_df.melt(\n",
    "        id_vars=[\"seed\", \"stage\", \"k\"],\n",
    "        value_vars=[\"theta10\", \"theta20\", \"theta21\", \"theta30\", \"theta31\"],\n",
    "        var_name=\"parameter\",\n",
    "        value_name=\"estimate\",\n",
    "    )\n",
    "    scaled_long = scaled_df.melt(\n",
    "        id_vars=[\"seed\", \"stage\", \"k\"],\n",
    "        value_vars=[\"theta10_scaled\", \"theta20_scaled\", \"theta21_scaled\", \"theta30_scaled\", \"theta31_scaled\"],\n",
    "        var_name=\"parameter\",\n",
    "        value_name=\"normalized_estimate\",\n",
    "    )\n",
    "\n",
    "    fig, axes = plt.subplots(1, 2, figsize=(18, 6))\n",
    "\n",
    "    sns.boxplot(\n",
    "        data=raw_long[raw_long[\"stage\"] == \"prime\"],\n",
    "        x=\"parameter\",\n",
    "        y=\"estimate\",\n",
    "        ax=axes[0],\n",
    "        palette=\"viridis\",\n",
    "    )\n",
    "    axes[0].set_title(\"最終 (prime) 推定量の分布\")\n",
    "    axes[0].tick_params(axis=\"x\", rotation=30)\n",
    "\n",
    "    sns.boxplot(\n",
    "        data=scaled_long[scaled_long[\"stage\"] == \"stage\"],\n",
    "        x=\"parameter\",\n",
    "        y=\"normalized_estimate\",\n",
    "        hue=\"k\",\n",
    "        ax=axes[1],\n",
    "        palette=\"Set2\",\n",
    "    )\n",
    "    axes[1].axhline(0.0, linestyle=\"--\", color=\"black\", linewidth=1)\n",
    "    axes[1].set_title(\"正規化推定量の分布 (各 k)\")\n",
    "    axes[1].tick_params(axis=\"x\", rotation=30)\n",
    "    axes[1].legend(title=\"k\", bbox_to_anchor=(1.02, 1), loc=\"upper left\")\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "plot_estimation_distributions(raw_estimates_df, scaled_estimates_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5dd9164e",
   "metadata": {},
   "source": [
    "---\n",
    "このノートブックでは、旧来の手組み式を `degenerate_diffusion` パッケージの疑似尤度コンポーネントで再構築し、閉形式推定の流れを段階別に整理しました。"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
